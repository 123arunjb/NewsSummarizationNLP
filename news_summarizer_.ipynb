{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k-IYDlZ7enTO",
    "outputId": "73859835-d907-46ef-f376-635eeddfc047"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vRPqYn3rK6ro",
    "outputId": "4787c009-374a-447c-9659-d85ac5fa6835"
   },
   "outputs": [],
   "source": [
    "! pip install rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tsO3Afviq2u3",
    "outputId": "b0dcf472-28d2-48ec-baac-361b9f3dc483"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from numpy.linalg import svd as singular_value_decomposition\n",
    "from nltk.corpus import stopwords\n",
    "from operator import attrgetter\n",
    "from collections import namedtuple\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "from rouge import Rouge\n",
    "import statistics\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aUWV_RDWmUbY"
   },
   "outputs": [],
   "source": [
    "#Please enter the path of new_summary.csv file\n",
    "df = pd.read_csv(\"news_summary.csv\",encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "Mz9-I9nmmowW",
    "outputId": "6c2c07d6-8071-40a2-8b8b-b8baec0bcfe1"
   },
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qiRzyzgYpWzf"
   },
   "outputs": [],
   "source": [
    "df['article'] = df['ctext']\n",
    "df['summary'] = df['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rYK9URqPDGct"
   },
   "source": [
    "Remove extra features like author, date, article link which does not affect news summary\n",
    "\n",
    "Drop the null values and reset index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "40ZtazMxnZj3"
   },
   "outputs": [],
   "source": [
    "df.drop(['author','date','read_more','text','ctext'],axis=1,inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "df.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GiOOg04XthAp"
   },
   "outputs": [],
   "source": [
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1sevIBiBtlEG"
   },
   "outputs": [],
   "source": [
    "def lemmatize_tokenize_text(text):\n",
    "    return [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)]\n",
    "\n",
    "def join_words(lst):\n",
    "  return ' '.join(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dJ2nT101Dm8H"
   },
   "source": [
    "Performing stemming and space tokenization to clean the article and summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q_qRxNMgtnya"
   },
   "outputs": [],
   "source": [
    "df['article'] = df['article'].apply(lemmatize_tokenize_text)\n",
    "df['summary'] = df['summary'].apply(lemmatize_tokenize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F01GMl9kvc-D"
   },
   "outputs": [],
   "source": [
    "df['article'] = df['article'].apply(join_words)\n",
    "df['summary'] = df['summary'].apply(join_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RDVL69z0ps6X",
    "outputId": "a19f5d39-e160-4eb4-818e-042503d9286e"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 140
    },
    "id": "UW8SLwompvkU",
    "outputId": "de17b514-2b5e-4a48-a2ef-582c04ca0207"
   },
   "outputs": [],
   "source": [
    "df['article'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "2DcxZaRRpzTV",
    "outputId": "56524ce8-869a-46a9-d171-8d960af9b573"
   },
   "outputs": [],
   "source": [
    "df['summary'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "InYef5hRAJqL"
   },
   "outputs": [],
   "source": [
    "stop_words = list(stopwords.words('english'))\n",
    "MIN_DIMENSIONS = 3\n",
    "REDUCTION_RATIO = 1/5\n",
    "SentenceInfo = namedtuple(\"SentenceInfo\", (\"sentence\", \"order\", \"rating\",))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aZ_Q2xk19qVu"
   },
   "outputs": [],
   "source": [
    "#Creating word dictionary, where key is the word and value is the row index\n",
    "#We also remove the stop words before adding them in dictionary and change everyone to lowercase\n",
    "def to_lower(word):\n",
    "  return word.lower()\n",
    "\n",
    "def create_dictionary(article):\n",
    "    words = word_tokenize(article)\n",
    "    words = tuple(words)\n",
    "    words = map(to_lower,words)\n",
    "    unique_words = frozenset(w for w in words if w not in stop_words)\n",
    "\n",
    "    return dict((w, i) for i, w in enumerate(unique_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Y0BDTk2DN5H"
   },
   "outputs": [],
   "source": [
    "#Create the word document matrix using text article and its corresponding dictionary\n",
    "#Sentance tokenize the article and then store the frequency(stored in dictionary) for words corresponding to each sentence\n",
    "def create_matrix(article, dictionary):\n",
    "    sentences = sent_tokenize(article)\n",
    "    words_count = len(dictionary)\n",
    "    sentences_count = len(sentences)\n",
    "    matrix = np.zeros((words_count, sentences_count))\n",
    "    for col, sentence in enumerate(sentences):\n",
    "        words = word_tokenize(sentence)\n",
    "        for word in words:\n",
    "            # only valid words is counted (not stop-words, ...)\n",
    "            if word in dictionary:\n",
    "                row = dictionary[word]\n",
    "                matrix[row, col] += 1\n",
    "\n",
    "    return matrix \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QCxwfyBGEYgC"
   },
   "outputs": [],
   "source": [
    "#Normalize the matrix by dividing each column with its max value\n",
    "def compute_term_freq(matrix):\n",
    "    smooth=0.4\n",
    "    max_word_frequencies = np.max(matrix, axis=0)\n",
    "    rows, cols = matrix.shape\n",
    "    for row in range(rows):\n",
    "        for col in range(cols):\n",
    "            max_word_frequency = max_word_frequencies[col]\n",
    "            if max_word_frequency != 0:\n",
    "                frequency = matrix[row, col]/max_word_frequency\n",
    "                matrix[row, col] = smooth + (1.0 - smooth)*frequency\n",
    "\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fld_HT9FG7kd"
   },
   "outputs": [],
   "source": [
    "#Perform truncated SVD by extracting the top topics and then multiplying them to get the ranks\n",
    "#We extract the top columns(columns having highest values) and multiply them with v_matrix\n",
    "def compute_rank(sigma, v_matrix):\n",
    "    dimensions = max(MIN_DIMENSIONS,int(len(sigma)*REDUCTION_RATIO))\n",
    "    powered_sigma = tuple(s**2 if i < dimensions else 0.0\n",
    "        for i, s in enumerate(sigma))\n",
    "\n",
    "    ranks = []\n",
    "    \n",
    "    for column_vector in v_matrix.T:\n",
    "        rank = sum(s*v**2 for s, v in zip(powered_sigma, column_vector))\n",
    "        ranks.append(math.sqrt(rank))\n",
    "\n",
    "    return ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1cw4DharH-hY"
   },
   "outputs": [],
   "source": [
    "class ItemsCount(object):\n",
    "    def __init__(self, value):\n",
    "        self._value = value\n",
    "\n",
    "    def __call__(self, sequence):\n",
    "        if isinstance(self._value, (bytes, str,)):\n",
    "            if self._value.endswith(\"%\"):\n",
    "                total_count = len(sequence)\n",
    "                percentage = int(self._value[:-1])\n",
    "                # at least one sentence should be chosen\n",
    "                count = max(1, total_count*percentage // 100)\n",
    "                return sequence[:count]\n",
    "            else:\n",
    "                return sequence[:int(self._value)]\n",
    "        elif isinstance(self._value, (int, float)):\n",
    "            return sequence[:int(self._value)]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return to_string(\"<ItemsCount: %r>\" % self._value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mDHTK0keK7_S"
   },
   "outputs": [],
   "source": [
    "#Returns the top sentences on the basis of their rating\n",
    "def get_top_sentence(sentences, count, rating, *args, **kwargs):\n",
    "    rate = rating\n",
    "    if isinstance(rating, dict):\n",
    "        rate = lambda s: rating[s]\n",
    "    \n",
    "    infos = (SentenceInfo(s, o, rate(s, *args, **kwargs))\n",
    "        for o, s in enumerate(sentences))\n",
    "    # sort sentences by rating in descending order\n",
    "    infos = sorted(infos, key=attrgetter(\"rating\"), reverse=True)\n",
    "    # get `count` first best rated sentences\n",
    "    if not isinstance(count, ItemsCount):\n",
    "        count = ItemsCount(count)\n",
    "    infos = count(infos)\n",
    "    # sort sentences by their order in document\n",
    "    infos = sorted(infos, key=attrgetter(\"order\"))\n",
    "\n",
    "    return tuple(i.sentence for i in infos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ugwUyzC8p2fX"
   },
   "outputs": [],
   "source": [
    "#Perform LSA Summarization\n",
    "def text_summarizer(article,summary_len=1):\n",
    "  article = str(article)\n",
    "  stop_words = list(stopwords.words('english'))\n",
    "  dictionary = create_dictionary(article)\n",
    "  sentences = sent_tokenize(article)\n",
    "  matrix = create_matrix(article,dictionary)\n",
    "  matrix = compute_term_freq(matrix)\n",
    "  u, sigma, v = singular_value_decomposition(matrix, full_matrices=False)\n",
    "  ranks = iter(compute_rank(sigma, v))\n",
    "  summarized_sentance = get_top_sentence(sentences,summary_len,lambda s: next(ranks))\n",
    "  return ' '.join(summarized_sentance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LYMHVZgJIwzM"
   },
   "source": [
    "We have assumed the best predicted summarized sentence(summary of length 1) to be our predicted_headline.\n",
    "\n",
    "We have applied text summarization on article to get predicted_summary of length 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KdNzaX_MLZik"
   },
   "outputs": [],
   "source": [
    "df['predicted_headline'] = df['article'].apply(text_summarizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IFlcH-CMVM3e"
   },
   "outputs": [],
   "source": [
    "df['predicted_summary'] = df['article'].apply(lambda x : text_summarizer(x,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "pF-Lwzs-ZYT6",
    "outputId": "bdaa9692-8480-4ddc-96ed-e9a5c31e40ba"
   },
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t_f8sCdSZwrK",
    "outputId": "34e3c21b-414f-4aad-f693-b4bc66b3b302"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kL1a5O9h3v9n"
   },
   "outputs": [],
   "source": [
    "#This function calculates the SVD similarity between 2 texts.\n",
    "#We first create matrix of both the texts and then factorize them\n",
    "#Then the u matrix is normalized and its 1st column is multiplied to get the topic similarity between 2 different texts\n",
    "def svd_similarity(text1,text2):\n",
    "  text1 = str(text1)\n",
    "  dictionary = create_dictionary(text1)\n",
    "  sentences = sent_tokenize(text1)\n",
    "  matrix = create_matrix(text1,dictionary)\n",
    "  matrix = compute_term_freq(matrix)\n",
    "  u1, sigma1, v1 = singular_value_decomposition(matrix, full_matrices=False) \n",
    "  text2 = str(text2)\n",
    "  dictionary = create_dictionary(text2)\n",
    "  sentences = sent_tokenize(text2)\n",
    "  matrix = create_matrix(text1,dictionary)\n",
    "  matrix = compute_term_freq(matrix)\n",
    "  u2, sigma2, v2 = singular_value_decomposition(matrix, full_matrices=False) \n",
    "  u1 = u1[:,0].reshape((u1.shape[0],1))\n",
    "  u2 = u2[:,0].reshape((u2.shape[0],1))\n",
    "  normalized_u1 = normalize(u1, axis=0).ravel()\n",
    "  normalized_u2 = normalize(u2, axis=0).ravel()\n",
    "  similarity = 0\n",
    "  for i in range(min(len(normalized_u1),len(normalized_u2))):\n",
    "    similarity += (normalized_u1[i]*normalized_u2[i])\n",
    "  return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WLoHFU3dXn7B"
   },
   "outputs": [],
   "source": [
    "#We calculated cosine similarity between 2 different texts\n",
    "def text_similarity(text1, text2):\n",
    "  count_vector = CountVectorizer()\n",
    "  corpus = [text1,text2]\n",
    "  X_train_counts = count_vector.fit_transform(corpus)\n",
    "  pd.DataFrame(X_train_counts.toarray(),columns=count_vector.get_feature_names_out (),index=['text1','text2'])\n",
    "  vectorizer = TfidfVectorizer()\n",
    "  trsfm=vectorizer.fit_transform(corpus)\n",
    "  pd.DataFrame(trsfm.toarray(),columns=vectorizer.get_feature_names_out (),index=['text1','text2'])\n",
    "  return cosine_similarity(trsfm[0:1], trsfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UP0rAA08ZgSE"
   },
   "outputs": [],
   "source": [
    "# We store the different evaluation metrix for each row (i.e cosine similarity, svd similarity, rouge-l score)\n",
    "headline_similarities = []\n",
    "summary_similarities = []\n",
    "svd_summary_similarities = []\n",
    "svd_headline_similarites = []\n",
    "f=[]\n",
    "p=[]\n",
    "r=[]\n",
    "for i in range(len(df['headlines'])):\n",
    "  ROUGE = Rouge()\n",
    "  headline_similarity = text_similarity(str(df['headlines'][i]),str(df['predicted_headline'][i]))\n",
    "  summary_similarity = text_similarity(str(df['summary'][i]),df['predicted_summary'][i])\n",
    "  svd_summary_similarity = svd_similarity(df['summary'][i],df['predicted_summary'][i])\n",
    "  svd_headline_similarity = svd_similarity(df['headlines'][i],df['predicted_headline'][i])\n",
    "  f.append(ROUGE.get_scores(df['summary'][i],df['predicted_summary'][i])[0]['rouge-l']['f'])\n",
    "  p.append(ROUGE.get_scores(df['summary'][i],df['predicted_summary'][i])[0]['rouge-l']['p'])\n",
    "  r.append(ROUGE.get_scores(df['summary'][i],df['predicted_summary'][i])[0]['rouge-l']['f'])\n",
    "  headline_similarities.append(headline_similarity[0][1])\n",
    "  summary_similarities.append(summary_similarity[0][1])\n",
    "  svd_summary_similarities.append(svd_summary_similarity)\n",
    "  svd_headline_similarites.append(svd_headline_similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CuTu4gmTL1lI"
   },
   "source": [
    "## Evaluation Metrices\n",
    "* Headline similarity scores tell us that using LSA summarization to predict headline is not a good aprroach.\n",
    "* While summary similarity scores shows that summary generated by LSA is nearly 76% similar to actual summary.\n",
    "* Cosine similarity is not correct way to evaluate the summary of article because it compares on the basis of words.\n",
    "* Rouge-l scores are used to evaluate abstractive summaries, while it is not a good evaluation metric for extractive summaries.\n",
    "* SVD similarity is more aprropriate evaluation metric for comparing the actual and predicted summary because we compare the summaries topic wise i.e how close they are to the same topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kkxC7V3e9umQ",
    "outputId": "61413d74-49f3-4db8-8ae8-e9f040d3c324"
   },
   "outputs": [],
   "source": [
    "print(\"Cosine similarity scores\")\n",
    "print(\"Mean Headline similarity score: \",statistics.mean(headline_similarities))\n",
    "print(\"Median Headline similarity score: \",statistics.mean(headline_similarities))\n",
    "print(\"Mean summary similarity score: \",statistics.mean(summary_similarities))\n",
    "print(\"Median summary similarity score: \",statistics.median(summary_similarities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ERqo_BHr_Jn5",
    "outputId": "96b8a821-7577-4ee6-8d71-f8d5527a3d6f"
   },
   "outputs": [],
   "source": [
    "print(\"SVD similarity scores\")\n",
    "print(\"Mean Headline similarity score: \",statistics.mean(svd_headline_similarites))\n",
    "print(\"Median Headline similarity score: \",statistics.mean(svd_headline_similarites))\n",
    "print(\"Mean summary similarity score: \",statistics.mean(svd_summary_similarities))\n",
    "print(\"Median summary similarity score: \",statistics.median(svd_summary_similarities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3U9YQQY5gmcx",
    "outputId": "2daf3d55-24ff-4c70-be83-80fb68ab8fb0"
   },
   "outputs": [],
   "source": [
    "print(\"ROUGE scores\")\n",
    "print(\"Mean summary similarity F1score: \",statistics.mean(f))\n",
    "print(\"Medaian summary similarity F1score: \",statistics.median(f))\n",
    "print(\"Mean summary similarity precision score: \",statistics.mean(p))\n",
    "print(\"Medaian summary similarity precision score: \",statistics.median(p))\n",
    "print(\"Mean summary similarity recall score: \",statistics.mean(r))\n",
    "print(\"Medaian summary similarity recall score: \",statistics.median(r))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "news-summarizer.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
